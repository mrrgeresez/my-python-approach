{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with OpenCV\n",
    "Install the latest versions of OpenCV and imutils (used to simplify code) depending on your OS and IDE.\n",
    "\n",
    "We will get straight into coding, explaining in each line its function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height=400, width=600, depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "# %matplotlib auto # to avoid not responding images windows\n",
    "\n",
    "image = cv2.imread(\"insomnio.jpg\")\n",
    "(h, w, d) = image.shape\n",
    "# in any array 3D you have the rows (height), columns (width) and depth(number of channels, if color=3)\n",
    "# that is how images are represented \n",
    "print(f\"height={h}, width={w}, depth={d}\")\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "# show image in new window\n",
    "cv2.waitKey(0)\n",
    "# waiting for clicking the image and push any key to continue execution\n",
    "# cv2.destroyAllWindows(); cv2.waitKey(1) # use it to show image and when clicked destroy it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the size of an image is presented as width (columns) x height (rows), e.g., 400x600=240000 px. Each pixel of a BW image has a value corresponding to its brightness in a grayscale bar, going from 0 to 255 (= 8bits resolution). In color images, let's start with the RGB space, which for historical reasons is used as BGR in opencv. It is represented as a 3-tuple with 256^3=16777216 combinations of colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=108, G=228, B=245\n"
     ]
    }
   ],
   "source": [
    "(B,G,R) = image[40,200]\n",
    "print(f\"R={R}, G={G}, B={B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array slicing\n",
    "The idea is to obtain a Region of Interest (ROI) for further processing. This action is can be automatically performed with deep learning or object tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi = image[0:170, 22:200]\n",
    "# slicing the rows and the columns\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image resizing\n",
    "To get a squared (or any other shaped) image, reduce the number of pixels for faster computation, fit size to specific case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we resize the image without accounting for the aspect ratio\n",
    "resized = cv2.resize(image, (800, 200)) # new width and height\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# to maintain aspect ratio is neccesary to compute the proportion and resize accordingly\n",
    "# with imutils a wrapper function does the job\n",
    "resized = imutils.resize(image, width=300) # provide width or height\n",
    "cv2.imshow(\"Imutils Resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image rotation\n",
    "Formally, we will need to calculate the point of rotation, in this case the center of the image. The rotation matrix is constructed with this information. Next we apply an affine transformation, a matrix multiplication (linear transformation) followed by a vector addition (translation), more specific, rotations (linear transformation), translations (vector addition) or scale operations (linear transformation).\n",
    "\n",
    "Again imutils save us tedious work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated = imutils.rotate(image, -45) # clockwise negative\n",
    "cv2.imshow(\"Imutils Rotation\", rotated)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# the image is cropped due to opencv not caring about what we actually did to the image\n",
    "# this function preserves the whole size\n",
    "rotated = imutils.rotate_bound(image, 45)\n",
    "cv2.imshow(\"Imutils Bound Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "Remove the high frequency content of images (like sharp edges) is useful for some algorithms or any other pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "# gaussian with 11x11 kernel with 0 standard deviation in both x-y\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing\n",
    "Any drawing operation is performed in-place (the original image is altered), therefore it is important to remember to create a copy and operate on this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a rectangle on the copied image\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (22, 0), (200, 170), (0, 0, 255), 2)\n",
    "# the position is defined as (x,y) in the in the top-left (origin) and bottom-right corners, forget the matrix notation\n",
    "# the color in BGR and the line thickness (negative value filled rectangle)\n",
    "cv2.circle(output, (300, 200), 20, (255, 0, 0), -1)\n",
    "# center coordinates, radius in px, color (blue), thickness (filled)\n",
    "cv2.line(output, (60, 80), (100, 300), (0, 0, 255), 5)\n",
    "# line beginning and end coordinates, color and thickness\n",
    "cv2.putText(output, \"Drawing like a pro\", (300, 250), \n",
    "\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 100), 2)\n",
    "# starting position,font used (generally sans-serif), scale, color and letter thickness\n",
    "cv2.imshow(\"Drawing\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real image processing\n",
    "Working on the terminal and processing the images depending on the final goal. A script must be created to interact with the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder:\n",
    "# to run script on python console use: run script_name args\n",
    "# to run script on OS terminal use: python (or python3) script_name.py args\n",
    "\n",
    "import argparse # terminal working\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"specify path to input image, relative or global\")\n",
    "args = vars(ap.parse_args())\n",
    "# vars transform the args.namespace to a keyword that can be used in a function\n",
    "\n",
    "# loading the input image via command line\n",
    "image = cv2.imread(args[\"image\"]) # args[\"image\"] = args.image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "# converting to grayscale for edge detection and thresholding\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Edge detecion with Canny algorithm\n",
    "edged = cv2.Canny(gray, 30, 150)\n",
    "# min threshold, max threshold, and sobel kernel size (default 3)\n",
    "# sobel filter: discrete differentiation operator, computing an approximation of the gradient of the image intensity function, enhancing high freq variations\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Thresholding\n",
    "# used to remove dark or light areas and highlight some regions\n",
    "# binary inverse threshold: in the image all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image, critical step for finding contours\n",
    "thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Detecting contours\n",
    "# using the thresholded image find the outlining\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "# simply finding white px in a copy of thresh\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "# compatibility wrapper for previous versions\n",
    "output = image.copy()\n",
    "# make copy when drawing over images\n",
    "for c in cnts:\n",
    "\t# draw each contour on the output image with a 3px thick purple\n",
    "\t# outline, then display the output contours one at a time\n",
    "\tcv2.drawContours(output, [c], -1, (240, 0, 159), 3)\n",
    "#     cv2.imshow(\"Contours\", output)\n",
    "# \tcv2.waitKey(0)\n",
    "    \n",
    "text = f\"{len(cnts)} objects found!\"\n",
    "cv2.putText(output, text, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t(240, 0, 159), 2)\n",
    "cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Erosions and dilations\n",
    "# To reduce noise in thresholded binary images\n",
    "# we apply erosions to reduce the size of foreground objects (eroding pixels)\n",
    "# useful for removing some blobs or undesired objects\n",
    "mask = thresh.copy()\n",
    "mask = cv2.erode(mask, None, iterations=5)\n",
    "# 5 iterations for reducing size\n",
    "cv2.imshow(\"Eroded\", mask)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Similarly dilations enlarge the ground and can combine foreground objects (nearby contours) when interested\n",
    "mask = thresh.copy()\n",
    "mask = cv2.dilate(mask, None, iterations=5)\n",
    "cv2.imshow(\"Dilated\", mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "### Masking\n",
    "# Mask out or hide regions we are not interested in, maybe to enchance some feature or the image.\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
